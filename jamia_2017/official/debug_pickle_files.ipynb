{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from experiments.baseline_experiment_util import setup_baseline_data\n",
    "from experiments.lr_model import model as lr_model\n",
    "from experiments.rf_model import model as rf_model\n",
    "from experiments.svm_model import model as svm_model\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_files_in = lambda dirname: [os.path.join(dirname, fname) for fname in os.listdir(dirname) if '.pkl' in fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/best_models_twitter/best_rf_sick_biased.pkl\n",
      "{\n",
      "  \"steps\": [\n",
      "    [\n",
      "      \"count\", \n",
      "      \"CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\\n        lowercase=True, max_df=0.77767276498823101, max_features=1000,\\n        min_df=1, ngram_range=(1, 2), preprocessor=None, stop_words=None,\\n        strip_accents=None, token_pattern=u'(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b',\\n        tokenizer=None, vocabulary=None)\"\n",
      "    ], \n",
      "    [\n",
      "      \"tfidf\", \n",
      "      \"TfidfTransformer(norm=None, smooth_idf=True, sublinear_tf=False,\\n         use_idf=False)\"\n",
      "    ], \n",
      "    [\n",
      "      \"rf\", \n",
      "      \"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_features='log2', max_leaf_nodes=None,\\n            min_impurity_split=1e-07, min_samples_leaf=1,\\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\\n            n_estimators=178, n_jobs=1, oob_score=True, random_state=0,\\n            verbose=0, warm_start=False)\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "################\n",
      "data/best_models_twitter/best_svm_sick_biased.pkl\n",
      "{\n",
      "  \"steps\": [\n",
      "    [\n",
      "      \"count\", \n",
      "      \"CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\\n        lowercase=True, max_df=0.75894291577334649, max_features=None,\\n        min_df=1, ngram_range=(1, 2), preprocessor=None, stop_words=None,\\n        strip_accents=None, token_pattern=u'(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b',\\n        tokenizer=None, vocabulary=None)\"\n",
      "    ], \n",
      "    [\n",
      "      \"tfidf\", \n",
      "      \"TfidfTransformer(norm=None, smooth_idf=True, sublinear_tf=False,\\n         use_idf=False)\"\n",
      "    ], \n",
      "    [\n",
      "      \"svc\", \n",
      "      \"SVC(C=0.071069812311930172, cache_size=200, class_weight=None, coef0=0.0,\\n  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\\n  max_iter=-1, probability=True, random_state=None, shrinking=True,\\n  tol=0.001, verbose=False)\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "################\n",
      "data/best_models_twitter/best_lr_sick_silver.pkl\n",
      "{\n",
      "  \"steps\": [\n",
      "    [\n",
      "      \"count\", \n",
      "      \"CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\\n        lowercase=True, max_df=0.88476193959827421, max_features=None,\\n        min_df=1, ngram_range=(1, 3), preprocessor=None, stop_words=None,\\n        strip_accents=None, token_pattern=u'(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b',\\n        tokenizer=None, vocabulary=None)\"\n",
      "    ], \n",
      "    [\n",
      "      \"tfidf\", \n",
      "      \"TfidfTransformer(norm=None, smooth_idf=True, sublinear_tf=False,\\n         use_idf=False)\"\n",
      "    ], \n",
      "    [\n",
      "      \"logreg\", \n",
      "      \"LogisticRegression(C=0.1446825123869821, class_weight=None, dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\\n          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "################\n",
      "data/best_models_twitter/best_rf_sick_silver.pkl\n",
      "{\n",
      "  \"steps\": [\n",
      "    [\n",
      "      \"count\", \n",
      "      \"CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\\n        lowercase=True, max_df=0.96347710344231019, max_features=1000,\\n        min_df=1, ngram_range=(1, 2), preprocessor=None, stop_words=None,\\n        strip_accents=None, token_pattern=u'(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b',\\n        tokenizer=None, vocabulary=None)\"\n",
      "    ], \n",
      "    [\n",
      "      \"tfidf\", \n",
      "      \"TfidfTransformer(norm=None, smooth_idf=True, sublinear_tf=False, use_idf=True)\"\n",
      "    ], \n",
      "    [\n",
      "      \"rf\", \n",
      "      \"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\\n            min_impurity_split=1e-07, min_samples_leaf=1,\\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\\n            n_estimators=191, n_jobs=1, oob_score=True, random_state=0,\\n            verbose=0, warm_start=False)\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "################\n",
      "data/best_models_twitter/best_lr_sick_biased.pkl\n",
      "{\n",
      "  \"steps\": [\n",
      "    [\n",
      "      \"count\", \n",
      "      \"CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\\n        lowercase=True, max_df=0.89871217241479107, max_features=None,\\n        min_df=1, ngram_range=(1, 3), preprocessor=None, stop_words=None,\\n        strip_accents=None, token_pattern=u'(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b',\\n        tokenizer=None, vocabulary=None)\"\n",
      "    ], \n",
      "    [\n",
      "      \"tfidf\", \n",
      "      \"TfidfTransformer(norm=None, smooth_idf=True, sublinear_tf=False,\\n         use_idf=False)\"\n",
      "    ], \n",
      "    [\n",
      "      \"logreg\", \n",
      "      \"LogisticRegression(C=0.18307382802953678, class_weight=None, dual=False,\\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\\n          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\\n          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "################\n"
     ]
    }
   ],
   "source": [
    "for fname in pickle_files_in('data/best_models_twitter/'):\n",
    "    model = joblib.load(fname)\n",
    "    print fname\n",
    "    print json.dumps(model.__dict__, default=str, indent=2)\n",
    "    print \"################\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
